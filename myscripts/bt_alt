#!/usr/bin/env ruby
# encoding: utf-8
# Another script to fetch torrents from other site. Written by Rainling.

require 'rubygems'
require 'open-uri'
require 'net/http'
require 'uri'
require 'hpricot'
require 'colorize'
require 'shellwords'
require 'date'

trap("INT") { exit 0 }

USER_AGENT = "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.8; rv:19.0) Gecko/20100101 Firefox/19.0"
uri = 'http://www.skymimi.com/'
path = "/Users/venj/Documents/Office_LAN"
proxy_addr = "127.0.0.1"
proxy_port = 8087
http = Net::HTTP
proxy = http::Proxy(proxy_addr, proxy_port)
proxy_whole = "http://#{proxy_addr}:#{proxy_port}"
isproxy = false
options = { :proxy => (isproxy ? proxy_whole : nil), "User-Agent" => USER_AGENT }
post_title = "最新BT合"

if isproxy
  puts "Using Proxy #{proxy_whole}"
else
  puts "No Proxy "
end

class CookieFetchError < StandardError;end

# 解析Cookie
print "Parsing Cookie...".magenta
cookie_regex = /document\.cookie='([^']+?)'/
doc_text = open(uri, options).read
if doc_text =~ cookie_regex
  doc_text.scan(cookie_regex) do |match|
    cookie = match[0].split(";").first
    if cookie.nil? or cookie.size == 0
      raise CookieFetchError.new("Cookie fetch failed. Site may updated!!!") 
    end
    options["Cookie"] = cookie
    puts "done.".green
  end
else
  puts "failed.".red
end

#open uri, options
if ARGV.size == 2
  from, to = ARGV[0].to_i, ARGV[1].to_i
elsif ARGV.size == 1
  from = to = ARGV[0].to_i
else
  from = to = 1
end

for i in from..to do
  url = "#{uri}forumdisplay.php?fid=55&page=#{i}"
  begin
    doc = Hpricot(open(url, options).read.encode("utf-8", "gb18030"))
    puts "Parsing page #{i}...".magenta
  rescue StandardError => err
    puts puts "Erro with #{url}: #{err.message}"
    next
  end

  doc.search("//table").each do |table|
    table_text = table.inner_html
    year = Time.now.year
    if table_text.include? post_title
      date_str = table.search("//.f_author/span").inner_text.strip
      year = date_str.split("-").first.to_i
      pdate = DateTime.parse(date_str)
      year -= 1 if pdate > DateTime.now
      year += 1 if (pdate + 1).year > pdate.year # For 1-01
    end
    
    next if year != Time.now.year # Skip old posts
    
    table.search("//a").each do |link|
      if link.inner_text.include? post_title
        dir_name = link.inner_text.sub('[', "[#{year}-")
        date_dir = File.join(path, dir_name) # Add year field to dir name.
        next if File.exist?(File.join(date_dir, ".finished"))
        url1 = "#{uri}#{link['href']}"
        begin
          mdoc = Hpricot(open(url1, options).read.encode("utf-8", "gb18030"))
          puts "Parsing thread #{link['href'].match(/tid=(\d+)/)[1]} (#{dir_name[1...dir_name.index(']')]})...".yellow
        rescue StandardError => err
          puts "Erro with #{url1}: #{err.message}"
          next
        end

        mdoc.search("//div.t_msgfont").each do |maindiv|
          mainhtml =  maindiv.inner_html
          mainhtml.gsub!("&nbsp;", "")
          regex = /(<img src=\".+?\" .+?>\s*<br\s*\/?>)+(\s*?)?<br\s*\/?>\s*?(Link URL:.+?)?(<a href=")?(http:\/\/[^"<]+).*?<br\s*\/>/im
          mainhtml.scan(regex) do |m|
            if !File.exist? date_dir
              Dir.mkdir date_dir
            end
            
            lk, code = m[4].split('=')
            turl ||= lk.split("?").first.sub(/link\.php/, "load.php")
            
            torrent_filename = File.join date_dir, "#{code}.torrent"
            if !File.exist?(torrent_filename)
              params = {}
              params["ref"] = code;
              url2 = URI.parse(turl)
              begin
                if isproxy
                  resp, data = proxy.post_form(url2, params)
                else
                  resp, data = http.post_form(url2, params)
                end
              rescue StandardError => err
                puts "Erro with #{url2}: #{err.message}"
                next
              end
              File.open(torrent_filename, 'wb+') do |f|
                f.syswrite(resp.body)
                puts "Torrent \"#{code}\" downloaded".green
              end
            end # End downloading torrent

            txt = m[0]
            regex2 = /<img src=\"(.+?)\" .+?>\s*<br\s*\/?>/i
            txt.scan(regex2).each_with_index do |n, icount|
              ext = n[0].split(".").last
              if ext.index("/") or ext.index("php")
                ext = "jpg"
              elsif ext.index("?")
                ext = ext.split("?").first
              end

              image_filename = File.join(date_dir, "#{code}_#{icount}.#{ext}")
              next if File.exists?(image_filename)

              begin
                print "Downloading #{File.basename(image_filename)}..."
                open(n[0], options) do |inf|
                  open(image_filename, "w+") do |ouf|
                    ouf.write(inf.read)
                    puts "done.".green
                  end
                end
              rescue StandardError => e
                if e.message.index("404")
                  puts "failed(404).".red
                else
                  puts "failed.".red
                  addon_arg = ""
                  if image_filename =~ /https/ || image_filename =~ /i\.na\.cx/
                    addon_arg = " --no-check-certificate"
                  end
                  $stderr.puts "\twget #{n[0]} -O #{image_filename.shellescape}#{addon_arg}"
                end
                next
              end # End downloading one pic
            end # End downloading pics
          end # End downloading torrents with pics
        end # End downloading all torrents in one thread.
        open(File.join(date_dir, ".finished"), "w+")
      end
    end # End Parsing one daily thread
  end # End Parsing all daily threads
end
